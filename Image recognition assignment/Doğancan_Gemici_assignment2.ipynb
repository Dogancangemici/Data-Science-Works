{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXPLORATION & PREPARATION (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "direction_encode = {'right': 0, 'left': 1, 'up': 2, 'straight': 3}\n",
    "eyewear_encode = {'open': 0, \"sunglasses\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_data = []\n",
    "files = \"./TrainingSet\"\n",
    "for myFile in os.listdir(files):\n",
    "    image_array = np.array(Image.open( files+ \"/\" + myFile ).convert('L')).flatten() #here i'm reaching the file and taking images and putting \n",
    "    X_data.append (image_array) #them into array and flattening each of them also i'm appending these files to list\n",
    "X_train = np.array(X_data) # converting my list to array\n",
    "\n",
    "directionlist = []\n",
    "for myFiles in os.listdir(files): \n",
    "    class_label = myFiles.split(\"_\")[1] #here is i'm doing split to take direction part in the file name.\n",
    "    directionlist.append(direction_encode[class_label]) #i'm collecting my values in list \n",
    "y_train_direction = np.array(directionlist) # converting my list to array\n",
    "\n",
    "\n",
    "\n",
    "X_datatest = []\n",
    "testfiles = \"./TestSet\"\n",
    "for myFile_test in os.listdir(testfiles):\n",
    "    image_array2 = np.array(Image.open( testfiles + \"/\" + myFile_test ).convert('L')).flatten() \n",
    "    X_datatest.append (image_array2) #i did same thing here as i did above nothing different\n",
    "X_test = np.array(X_datatest)\n",
    "\n",
    "\n",
    "directionlist_test = []\n",
    "for myFiles3 in os.listdir(testfiles):\n",
    "    test_label = myFiles3.split(\"_\")[1]  #here is i'm doing split to take direction part in the filename.\n",
    "    directionlist_test.append(direction_encode[test_label])\n",
    "y_test_direction = np.array(directionlist_test)\n",
    "\n",
    "eyelist = []\n",
    "for myFiles2 in os.listdir(files): \n",
    "    class_label2 = myFiles2.split(\"_\")[3]   #reaching files and splitting first with \"_\" then with \".\" to get rid of JPG part \n",
    "    class_labelname = class_label2.split(\".\")[0] # so i can get open or sunglasses part in filename.\n",
    "    eyelist.append(eyewear_encode[class_labelname])\n",
    "y_train_eyewear = np.array(eyelist)\n",
    "\n",
    "\n",
    "eyelist_test = []\n",
    "for myFiles4 in os.listdir(testfiles):\n",
    "    test_label2 = myFiles4.split(\"_\")[3]\n",
    "    test_labelname = test_label2.split(\".\")[0]  #same as i did above. exactly same things! but for test files.\n",
    "    eyelist_test.append(eyewear_encode[test_labelname])\n",
    "y_test_eyewear = np.array(eyelist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "12\n",
      "104\n",
      "12\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# DON'T ERASE THIS PART\n",
    "print(sum(X_train[3][3:6]))\n",
    "print(sum(y_train_direction[-6:]))\n",
    "print(sum(X_test[3][3:6]))\n",
    "print(sum(y_test_direction[-6:]))\n",
    "print(sum(y_train_eyewear[-6:]))\n",
    "print(sum(y_test_eyewear[-6:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION MODEL TO PREDICT DIRECTION FACED (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'kernel': ('linear', 'rbf', 'poly'), 'C': [0.1, 0.5, 1.0], 'decision_function_shape': ('ovo', 'ovr'), 'tol': [0.0001, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf','poly'), 'C':[0.1,0.5,1.0], 'tol':[0.0001,0.001], 'decision_function_shape':('ovo','ovr')}\n",
    "svc= svm.SVC(random_state=0)  #first giving parameters and defining svc \n",
    "clf = GridSearchCV(svc, parameters, cv=5,scoring= \"accuracy\") # then try to find best parameters by gridsearch\n",
    "clf.fit(X_train, y_train_direction) #fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_labels = clf.predict(X_train)  #having prediction for train data\n",
    "best_parameters = clf.best_params_  #to get best parameters\n",
    "training_accuracy = accuracy_score(y_train_direction, predicted_labels)  #to observe training accuracy\n",
    "validation_accuracy = clf.best_score_ # best_score_ gives validation score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 0.1, 'decision_function_shape': 'ovo', 'tol': 0.0001}\n",
      "1.0\n",
      "0.8063492063492064\n"
     ]
    }
   ],
   "source": [
    "print(best_parameters)\n",
    "print(training_accuracy)\n",
    "print(validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "predictiontest = clf.predict(X_test)  #having prediction for test data to get accuracy\n",
    "test_accuracy = accuracy_score(y_test_direction,predictiontest)  # having test accuracy\n",
    "test_precision = precision_score(y_test_direction,predictiontest, average=\"weighted\") # having test_precision\n",
    "test_recall = recall_score(y_test_direction,predictiontest, average=\"weighted\") # having test recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888888888888889\n",
      "0.9893939393939394\n",
      "0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy)\n",
    "print(test_precision)\n",
    "print(test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did your model perform well on both training and test data? If no, does it underfit or overfit? Write your answer the corresponding cell in the template with a precise explanation. Write your answer below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it performed well on both training and test data. but there is little difference that it performed in training data better than test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc1= svm.SVC(kernel= 'linear', C=0.1, decision_function_shape='ovo', tol= 0.0001,random_state=0)\n",
    "#here i'm defining my svc with best parameters that i found in part a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindata = []\n",
    "testdata = []\n",
    "ilist = []\n",
    "for i in range(15,316,15): \n",
    "    svc1.fit(X_train[:i], y_train_direction[:i])   #fitting data to my model with i steps \n",
    "    X_train_predict = svc1.predict(X_train)  # having training prediction for accuracy score\n",
    "    X_test_predict = svc1.predict(X_test) # having test prediction for accuracy score\n",
    "    training_misclassified =1 -  accuracy_score(y_train_direction,X_train_predict) #finding misclassified by using accuracy and\n",
    "    test_misclassified =1 -  accuracy_score(y_test_direction,X_test_predict) # subtracting from 1\n",
    "    traindata.append(training_misclassified) # keeping this data in list to show in learning curve\n",
    "    testdata.append(test_misclassified)\n",
    "    ilist.append(i) # i have to keep \"i\" as well to draw my learning curve healthier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa004048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ilist, traindata,linewidth=2, label='train')  # here drawing learning curve of train data by using misclassified samples\n",
    "plt.plot(ilist, testdata,linewidth=2, label='test') # and here for test data\n",
    "plt.legend(loc=\"upper right\", fontsize=12)  # for text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION MODEL TO PREDICT EYEWEAR (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'kernel': ('linear', 'rbf', 'poly'), 'C': [0.1, 0.5, 1.0], 'decision_function_shape': ('ovo', 'ovr'), 'tol': [0.0001, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf','poly'), 'C':[0.1,0.5,1.0], 'tol':[0.0001,0.001], 'decision_function_shape':('ovo','ovr')}\n",
    "svc_eye= svm.SVC(random_state=0)\n",
    "clf_eye = GridSearchCV(svc_eye, parameters, cv=5,scoring= \"accuracy\")\n",
    "clf_eye.fit(X_train, y_train_eyewear)  # i did same things that i have done for direction data like defining svc and looking for\n",
    "#best parameters in given parameters by gridsearch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ('l1', 'l2'), 'C': [0.001, 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters_lr = {'penalty':('l1', 'l2'), 'C':[0.001, 0.01, 0.1]} # they are parameters for logistic regression\n",
    "lr = LogisticRegression(random_state=0, solver = \"saga\") # here i'm defining logistic regression\n",
    "clf_lr_eye = GridSearchCV(lr, parameters_lr, cv=5,scoring= \"accuracy\")  # searching best paramters for logistic regression\n",
    "clf_lr_eye.fit(X_train, y_train_eyewear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels_eye = clf_eye.predict(X_train) # prediction with svc\n",
    "predicted_labels_lr_eye = clf_lr_eye.predict(X_train) # prediction with logistic reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_parameters_SVC = clf_eye.best_params_  #best parameters of svc\n",
    "best_parameters_LR = clf_lr_eye.best_params_ # best paramters of lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "training_accuracy_SVC =accuracy_score(y_train_eyewear, predicted_labels_eye) #having training accuracy for svc model\n",
    "validation_accuracy_SVC = clf_eye.best_score_ # validation score for svc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_accuracy_LR = accuracy_score(y_train_eyewear, predicted_labels_lr_eye) # training accuracy for lr model\n",
    "validation_accuracy_LR = clf_lr_eye.best_score_ # validation score for lr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RESULTS\n",
      "{'kernel': 'poly', 'C': 0.1, 'decision_function_shape': 'ovo', 'tol': 0.0001}\n",
      "1.0\n",
      "0.6222222222222222\n",
      "\n",
      "LR RESULTS\n",
      "{'penalty': 'l2', 'C': 0.001}\n",
      "1.0\n",
      "0.5968253968253968\n"
     ]
    }
   ],
   "source": [
    "print(\"SVC RESULTS\")\n",
    "print(best_parameters_SVC)\n",
    "print(training_accuracy_SVC)\n",
    "print(validation_accuracy_SVC)\n",
    "print(\"\\nLR RESULTS\")\n",
    "print(best_parameters_LR)\n",
    "print(training_accuracy_LR)\n",
    "print(validation_accuracy_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_preds = clf_eye.predict(X_test) # using same model SVC that i've created above and predicting with test data\n",
    "LR_preds = clf_lr_eye.predict(X_test) # using same model LR that i've created above and predicting with test data \n",
    "#so i will decide which model will work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_SVC = accuracy_score(y_test_eyewear,SVC_preds) # calculating accuracy for test data with SVC model\n",
    "precision_SVC = precision_score(y_test_eyewear,SVC_preds, average=\"weighted\") #its precision\n",
    "recall_SVC =recall_score(y_test_eyewear,SVC_preds, average=\"weighted\") #its recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_LR = accuracy_score(y_test_eyewear,LR_preds) #calculating accuracy for test data with LR model\n",
    "precision_LR = precision_score(y_test_eyewear,LR_preds, average=\"weighted\") # its precision\n",
    "recall_LR =recall_score(y_test_eyewear,LR_preds, average=\"weighted\") #its recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RESULTS\n",
      "0.7777777777777778\n",
      "0.7791184850008379\n",
      "0.7777777777777778\n",
      "\n",
      "LR RESULTS\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"SVC RESULTS\")\n",
    "print(accuracy_SVC)\n",
    "print(precision_SVC)\n",
    "print(recall_SVC)\n",
    "print(\"\\nLR RESULTS\")\n",
    "print(accuracy_LR)\n",
    "print(precision_LR)\n",
    "print(recall_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which modelâ€™s performance is the best? Write your answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC model performances is better than LR as it is seen above. In SVC results, accuracy, precision and recall are higher than LR results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Logistic Regression and SVC models perform well on both training and test data? If no, do they underfit or overfit? Write your answer below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They do not perform very well. Because they are overfitting. While training accuracy is 1.0 validation accuracies are low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL EXPLORATION - EYEWEAR PREDICTION (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will try to increase accuracy on X_test (Remember that you should never use test data for training and model tuning. Do the model selection/tuning with cross validation on training data). You may use different models or parameters (Notice that, so far, you tried only a small list of values for parameters such C in the grid search). You may also try to extract new features from images. Your aim is to get a higher test accuracy than the one you got in part (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=150).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'max_iter': 50, 'tol': 0.0001, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'gamma':[1,0.0001,0.001,0.1], 'max_iter' : [10,50,100,150], 'C':[0.1,0.2,0.08,0.04,0.01], 'tol':[0.0001,0.00015,0.00001]}\n",
    "svc_final= svm.SVC(random_state=0, kernel ='poly',decision_function_shape='ovo')\n",
    "clf_final = GridSearchCV(svc_final, parameters, cv=5,scoring= \"accuracy\")\n",
    "clf_final.fit(X_train, y_train_eyewear)\n",
    "print(clf_final.best_params_)  #here i was trying to do same things that i've done above like using svc and looking best parameters\n",
    "# but i found more parameters to give gridsearcher and find better accuracy. as it is seen i have more varieties of paramaters\n",
    "# i printed best parameters to observe the difference between this and previous one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "#final_pred_train = clf_final.predict(X_train)   # i tried test data with best paramaters but it did not give me better accuracy\n",
    "#final_pred_test = clf_final.predict(X_test)   # as it is seen clf_final is my model here and i tried with this but accuracy \n",
    "#train_accuracy = accuracy_score(y_train_eyewear, final_pred_train) # lower than i found and i was trying to give different \n",
    "#test_accuracy =  accuracy_score(y_test_eyewear, final_pred_test) #parameters but it was taking a lot time. so i decided to try\n",
    " # manually as it is seen below. so i did not want to run this code because of confusion of variables. i will leave all of it \n",
    "# as a comment. if you like to run you can do it as well. thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogancan\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(random_state = 0, kernel ='poly',decision_function_shape='ovo', max_iter = 100, C = 1, tol = 0.0001, gamma = 0.0001)\n",
    "#in the line above, i was trying different parameters because as i mentioned above grid search working so slow,\n",
    "#and i found max_iter = 100 have better accuracy with test data \n",
    "model.fit(X_train, y_train_eyewear) # my aim was trying to increase test data so i do not work with model that i found the best\n",
    "final_pred_train = model.predict(X_train) # for training data. so it is different and i have better accuracy even if it's so little\n",
    "final_pred_test = model.predict(X_test) # here i'm predicting.\n",
    "train_accuracy = accuracy_score(y_train_eyewear, final_pred_train)\n",
    "test_accuracy =  accuracy_score(y_test_eyewear, final_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training accuracy still 1.0 and test accuracy increased from 0.77777 to 0.788889 :)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
